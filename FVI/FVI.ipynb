{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed13e3f4-0ca0-4584-99fd-1b24c619cf21",
   "metadata": {},
   "source": [
    "This code comes: https://github.com/hanbingyan/FVIOT/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edf8d7a-2b21-4a40-afa1-3159ddfd74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(12345)\n",
    "np.random.seed(12345)\n",
    "torch.manual_seed(12345)\n",
    "# check gpu is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Config\n",
    "MEM_SIZE = 3000\n",
    "BATCH_SIZE = 80\n",
    "DISCOUNT = 1.0\n",
    "N_INSTANCE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6d8b1-cb73-4321-8575-bceef17f2bfb",
   "metadata": {},
   "source": [
    "Utility functions for a more compact code and for the optimisation of the nerual networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af0eccd-6725-4242-b27f-667020e53863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch.nn as nn\n",
    "\n",
    "# def sinkhorn_knopp(mu, nu, C, reg, niter):\n",
    "#     K = np.exp(-C/C.max()/reg)\n",
    "#     u = np.ones((len(mu), ))\n",
    "#     for i in range(1, niter):\n",
    "#         v = nu/np.dot(K.T, u)\n",
    "#         u = mu/(np.dot(K, v))\n",
    "#     Pi = np.diag(u) @ K @ np.diag(v)\n",
    "#     return Pi\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition', ('time', 'x', 'y', 'value'))\n",
    "\n",
    "class Memory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def clear(self):\n",
    "        self.memory.clear()\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, memory, optimizer, Trunc_flag):\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    values_batch = torch.stack(batch.value)\n",
    "    x_batch = torch.stack(batch.x)\n",
    "    y_batch = torch.stack(batch.y)\n",
    "    time_batch = torch.stack(batch.time)\n",
    "\n",
    "    left_values = policy_net(time_batch, x_batch, y_batch)\n",
    "\n",
    "    # # Compute the expected Q values\n",
    "    Loss_fn = nn.SmoothL1Loss()\n",
    "    # Loss_fn = nn.MSELoss()\n",
    "    loss = Loss_fn(left_values, values_batch)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    if Trunc_flag:\n",
    "        for param in policy_net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5008f3da-9a6a-49e4-aa09-8ab14e0b776e",
   "metadata": {},
   "source": [
    "The neural network at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04caccf1-804c-4832-bd22-cd0115d9b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nbimporter\n",
    "\n",
    "h = 8\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim, T):\n",
    "        super(DQN, self).__init__()\n",
    "        self.T = T\n",
    "        self.linear1 = nn.Linear(x_dim+y_dim, h)\n",
    "        # self.linear1.weight.data.fill_(10.0)\n",
    "        # torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        # torch.nn.init.zeros_(self.linear1.weight)\n",
    "        # torch.nn.init.zeros_(self.linear1.bias)\n",
    "        # self.bn = nn.BatchNorm1d(h)\n",
    "        self.linear2 = nn.Linear(h, h)\n",
    "        # torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        # torch.nn.init.zeros_(self.linear2.bias)\n",
    "        # torch.nn.init.zeros_(self.linear2.weight)\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.linear3 = nn.Linear(h, 1)\n",
    "\n",
    "        self.linear5 = nn.Linear(2, 1)\n",
    "        # torch.nn.init.zeros_(self.linear5.bias)\n",
    "        # torch.nn.init.zeros_(self.linear5.weight)\n",
    "        # torch.nn.init.xavier_uniform_(self.linear5.weight)\n",
    "        self.linear6 = nn.Linear(2, 1)\n",
    "        # torch.nn.init.zeros_(self.linear6.bias)\n",
    "\n",
    "    def forward(self, time, x, y):\n",
    "        state = torch.cat((x, y), dim=1)\n",
    "        state = torch.relu(self.linear1(state))\n",
    "        # state = self.bn(state)\n",
    "        state = torch.relu(self.linear2(state))\n",
    "        # state = self.dropout(state)\n",
    "        state = torch.sigmoid(self.linear3(state))\n",
    "        time_f2 = torch.cat((self.T - time, (self.T - time)**2), dim=1)\n",
    "        time_f1 =  self.linear5(time_f2)\n",
    "        time_f2 = self.linear6(time_f2)\n",
    "        return state*time_f1 + time_f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5a484-11a1-499c-8eb0-eb1eee366357",
   "metadata": {},
   "source": [
    "The code to compute the Adapted Wasserstein distance (AW_2) between two brownian path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc842d-b1c8-4bd4-87e1-fe45a11a8664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 4 Loss 0.0006122382645116886\n",
      "Time step 3 Loss 4.415977704524994\n",
      "Time step 2 Loss 2.4819213271141054\n",
      "Time step 1 Loss 1.2711868703365325\n",
      "Time step 0 Loss 0.2843217607587576\n",
      "Instance 0\n",
      "Last values 6.015169620513916\n",
      "Time step 4 Loss 0.0018359368987148628\n",
      "Time step 3 Loss 3.56169570684433\n",
      "Time step 2 Loss 2.42690686583519\n",
      "Time step 1 Loss 1.010173037648201\n",
      "Time step 0 Loss 0.5052285067737102\n",
      "Instance 1\n",
      "Last values 7.117129325866699\n",
      "Time step 4 Loss 0.017255221891537074\n",
      "Time step 3 Loss 3.9723653316497805\n",
      "Time step 2 Loss 2.767244482040405\n",
      "Time step 1 Loss 1.8418561697006226\n",
      "Time step 0 Loss 1.3509894859045743\n",
      "Instance 2\n",
      "Last values 5.763694763183594\n",
      "Time step 4 Loss 0.01835930245288182\n",
      "Time step 3 Loss 3.9306265115737915\n",
      "Time step 2 Loss 2.5592572927474975\n",
      "Time step 1 Loss 0.7846329852938652\n",
      "Time step 0 Loss 0.269201698154211\n",
      "Instance 3\n",
      "Last values 6.723105430603027\n",
      "Time step 4 Loss 0.27581188827753067\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import ot\n",
    "import time as Clock\n",
    "\n",
    "start = Clock.time()\n",
    "\n",
    "####### One-dimensional case #########\n",
    "# with parameter constraint\n",
    "Trunc_flag = True\n",
    "# No. of gradient descent steps (G)\n",
    "N_OPT = 20\n",
    "# No. of sample paths (N)\n",
    "smp_size = 2000\n",
    "# Sample size for empirical OT (B)\n",
    "in_sample_size = 50\n",
    "\n",
    "time_horizon = 4\n",
    "x_dim = 1\n",
    "y_dim = 1\n",
    "x_vol = 1.0\n",
    "y_vol = 0.5\n",
    "x_init = 1.0\n",
    "y_init = 2.0\n",
    "\n",
    "\n",
    "###### Multidimensional case #########\n",
    "## no parameter constraint\n",
    "# Trunc_flag = False\n",
    "# time_horizon = 5\n",
    "# x_dim = 5\n",
    "# y_dim = 5\n",
    "# x_vol = 1.1\n",
    "# y_vol = 0.1\n",
    "# x_init = 1.0\n",
    "# y_init = 2.0\n",
    "# N_OPT = 400\n",
    "# smp_size = 4000\n",
    "# in_sample_size = 300\n",
    "\n",
    "\n",
    "final_result = np.zeros(N_INSTANCE)\n",
    "\n",
    "for n_ins in range(N_INSTANCE):\n",
    "\n",
    "    val_hist = np.zeros(time_horizon+1)\n",
    "    loss_hist = np.zeros(time_horizon+1)\n",
    "\n",
    "    memory = Memory(MEM_SIZE)\n",
    "    policy_net = DQN(x_dim, y_dim, time_horizon).to(device)\n",
    "    target_net = DQN(x_dim, y_dim, time_horizon).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "    # optimizer = optim.SGD(policy_net.parameters(), lr=0.1, momentum=0.9)\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=1e-2) # weight_decay=1e-3)\n",
    "\n",
    "    x_path_pool = torch.zeros(smp_size, time_horizon+1, x_dim, device=device)\n",
    "    y_path_pool = torch.zeros(smp_size, time_horizon+1, y_dim, device=device)\n",
    "    x_path_pool[:, 0, :] = x_init\n",
    "    y_path_pool[:, 0, :] = y_init\n",
    "\n",
    "    for smp_id in range(smp_size):\n",
    "        # sample many paths in advance\n",
    "        for t in range(1, time_horizon + 1):\n",
    "            x_path_pool[smp_id, t, :] = x_path_pool[smp_id, t - 1, :] + x_vol * torch.randn(x_dim, device=device)\n",
    "            y_path_pool[smp_id, t, :] = y_path_pool[smp_id, t - 1, :] + y_vol * torch.randn(y_dim, device=device)\n",
    "\n",
    "    for time in range(time_horizon, -1, -1):\n",
    "\n",
    "        for smp_id in range(smp_size):\n",
    "            x_mvn = MultivariateNormal(loc=x_path_pool[smp_id, time, :], covariance_matrix=torch.eye(x_dim, device=device)*x_vol**2)\n",
    "            y_mvn = MultivariateNormal(loc=y_path_pool[smp_id, time, :], covariance_matrix=torch.eye(y_dim, device=device)*y_vol**2)\n",
    "            next_x = x_mvn.sample((in_sample_size,))\n",
    "            next_y = y_mvn.sample((in_sample_size,))\n",
    "\n",
    "            x_batch = torch.repeat_interleave(next_x, repeats=in_sample_size, dim=0)\n",
    "            y_batch = torch.tile(next_y, (in_sample_size, 1))\n",
    "            l2_mat = torch.sum((x_batch - y_batch)**2, dim=1)\n",
    "\n",
    "            if time == time_horizon:\n",
    "                expected_v = 0.0\n",
    "            elif time == time_horizon-1:\n",
    "                min_obj = l2_mat.reshape(in_sample_size, in_sample_size)\n",
    "                expected_v = ot.emd2(np.ones(in_sample_size) / in_sample_size, np.ones(in_sample_size) / in_sample_size,\n",
    "                                     min_obj.detach().cpu().numpy())\n",
    "            else:\n",
    "                val = target_net(torch.ones(x_batch.shape[0], 1, device=device)*(time+1.0), x_batch, y_batch).reshape(-1)\n",
    "                min_obj = (l2_mat + DISCOUNT*val).reshape(in_sample_size, in_sample_size)\n",
    "                expected_v = ot.emd2(np.ones(in_sample_size)/in_sample_size, np.ones(in_sample_size)/in_sample_size,\n",
    "                                     min_obj.detach().cpu().numpy())\n",
    "\n",
    "            memory.push(torch.tensor([time], dtype=torch.float32, device=device), x_path_pool[smp_id, time, :],\n",
    "                        y_path_pool[smp_id, time, :], torch.tensor([expected_v], device=device))\n",
    "\n",
    "        # Optimize at time t\n",
    "        for opt_step in range(N_OPT):\n",
    "            loss = optimize_model(policy_net, memory, optimizer, Trunc_flag)\n",
    "            if Trunc_flag:\n",
    "                with torch.no_grad():\n",
    "                    for param in policy_net.parameters():\n",
    "                        ## param.add_(torch.randn(param.size(), device=device)/50)\n",
    "                        param.clamp_(-1.0, 1.0)\n",
    "            if loss:\n",
    "                loss_hist[time] += loss.detach().cpu().item()\n",
    "\n",
    "\n",
    "        loss_hist[time] /= N_OPT\n",
    "\n",
    "        # update target network\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        # test initial value\n",
    "        val = target_net(torch.ones(1, 1, device=device)*0.0, x_path_pool[0, 0, :].reshape(1, x_dim),\n",
    "                         y_path_pool[0, 0, :].reshape(1, y_dim)).reshape(-1)\n",
    "        val_hist[time] = val\n",
    "\n",
    "        # empty memory\n",
    "        memory.clear()\n",
    "        print('Time step', time, 'Loss', loss_hist[time])\n",
    "\n",
    "        # print('Shift vector in the last layer:', target_net.linear3.bias.sum().item())\n",
    "\n",
    "\n",
    "    # for name, param in target_net.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(name, param.data)\n",
    "\n",
    "\n",
    "    print('Instance', n_ins)\n",
    "    # print('Time elapsed', end - start)\n",
    "    print('Last values', val_hist[0])\n",
    "    final_result[n_ins] = val_hist[0]\n",
    "\n",
    "print('All final value:', final_result)\n",
    "print('Final mean:', final_result.mean())\n",
    "print('Final std:', final_result.std())\n",
    "end = Clock.time()\n",
    "print('Average time for one instance:', (end-start)/N_INSTANCE)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(val_hist)\n",
    "# plt.xlabel('Steps', fontsize=16)\n",
    "# plt.ylabel(r'$V_0$', fontsize=16)\n",
    "# # plt.tick_params(axis = 'both', which = 'major', labelsize = 16)\n",
    "# plt.legend(bbox_to_anchor=(1, 1), title='', fontsize=16, title_fontsize=16)\n",
    "# plt.savefig('conti_val.pdf', format='pdf', dpi=1000, bbox_inches='tight', pad_inches=0.1)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(loss_hist)\n",
    "# plt.xlabel('Steps', fontsize=16)\n",
    "# plt.ylabel('Loss', fontsize=16)\n",
    "# plt.savefig('conti_loss.pdf', format='pdf', dpi=1000, bbox_inches='tight', pad_inches=0.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec2e2b-e9e2-4e7f-bb23-9b9de28706f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7dbd0b-7d50-4b20-bb00-b0a268973091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
