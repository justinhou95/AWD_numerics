{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT SURE THIS WORKS -> will check later Now for markov use the other code in utils_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot  # POT library for optimal transport\n",
    "\n",
    "# Helper: convert a value to a hashable type.\n",
    "def to_hashable(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return tuple(x.tolist())\n",
    "    return x\n",
    "\n",
    "###############################################################################\n",
    "# 1. MARKOV (RECOMBINING) TREE DATA STRUCTURE\n",
    "###############################################################################\n",
    "\n",
    "class MarkovTreeNode:\n",
    "    \"\"\"\n",
    "    A node for a recombining (Markov) tree.\n",
    "    \n",
    "    Each node holds a state value and a dictionary of children.\n",
    "    The keys of the dictionary are hashable versions of the child state.\n",
    "    Each entry is a tuple (child_node, cumulative_weight) that will later be\n",
    "    normalized to represent the transition probability.\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.children = {}  # key -> (child_node, cumulative_weight)\n",
    "\n",
    "    def add_child(self, child_node, weight):\n",
    "        key = to_hashable(child_node.value)\n",
    "        if key in self.children:\n",
    "            existing_node, cum_weight = self.children[key]\n",
    "            self.children[key] = (existing_node, cum_weight + weight)\n",
    "        else:\n",
    "            self.children[key] = (child_node, weight)\n",
    "\n",
    "def build_markov_tree_from_paths(sample_paths, weights):\n",
    "    \"\"\"\n",
    "    Builds a recombining (Markov) tree from sample paths.\n",
    "    \n",
    "    For a Markov process the next state depends only on the current state.\n",
    "    Therefore, if two paths share the same state at a given time step, they are merged.\n",
    "    \n",
    "    Parameters:\n",
    "      sample_paths (list of lists): Each inner list is a path (sequence of states).\n",
    "      weights (list or array): A weight associated with each sample path.\n",
    "      \n",
    "    Returns:\n",
    "      MarkovTreeNode: The root node of the recombining tree.\n",
    "    \"\"\"\n",
    "    if len(sample_paths) == 0:\n",
    "        raise ValueError(\"No sample paths provided.\")\n",
    "    \n",
    "    # Ensure all sample paths start at the same state.\n",
    "    initial_state = sample_paths[0][0]\n",
    "    for path in sample_paths:\n",
    "        if to_hashable(path[0]) != to_hashable(initial_state):\n",
    "            raise ValueError(\"All sample paths must have the same initial state.\")\n",
    "    \n",
    "    # Create the root node.\n",
    "    root = MarkovTreeNode(initial_state)\n",
    "    \n",
    "    # Insert each path into the tree.\n",
    "    for path, weight in zip(sample_paths, weights):\n",
    "        current_node = root\n",
    "        for state in path[1:]:\n",
    "            key = to_hashable(state)\n",
    "            if key in current_node.children:\n",
    "                child_node, cum_weight = current_node.children[key]\n",
    "                current_node.children[key] = (child_node, cum_weight + weight)\n",
    "            else:\n",
    "                child_node = MarkovTreeNode(state)\n",
    "                current_node.children[key] = (child_node, weight)\n",
    "            current_node = child_node\n",
    "\n",
    "    # Normalize the children weights to obtain transition probabilities.\n",
    "    def normalize_transitions(node):\n",
    "        total_weight = sum(prob for (_, prob) in node.children.values())\n",
    "        if total_weight > 0:\n",
    "            for key in node.children:\n",
    "                child, cum_weight = node.children[key]\n",
    "                node.children[key] = (child, cum_weight / total_weight)\n",
    "                normalize_transitions(child)\n",
    "    normalize_transitions(root)\n",
    "    return root\n",
    "\n",
    "###############################################################################\n",
    "# 2. RECURSIVE ADAPTED WASSERSTEIN DISTANCE (NESTED) FOR MARKOV PROCESSES\n",
    "###############################################################################\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def nested_transport_cost(\n",
    "    node1, node2, current_depth, max_depth, power, method=\"lp\", lambda_reg=1e-2, pbar=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursively computes the nested (adapted Wasserstein) cost between two nodes.\n",
    "    \n",
    "    Parameters:\n",
    "      node1, node2: MarkovTreeNode objects at the same depth.\n",
    "      current_depth: Current depth (starting at 0).\n",
    "      max_depth: Maximum depth (number of transitions) to consider.\n",
    "      power: Exponent for the cost (e.g., 1 for absolute difference, 2 for squared difference).\n",
    "      method: (unused here; placeholder if one wants to switch solvers).\n",
    "      lambda_reg: Regularization parameter (unused in the LP solver version).\n",
    "      pbar: Progress bar instance (used for tracking recursion depth).\n",
    "\n",
    "    Returns:\n",
    "      Total nested cost between node1 and node2.\n",
    "    \"\"\"\n",
    "    # Initialize the progress bar only at the first call\n",
    "    if current_depth == 0 and pbar is None:\n",
    "        pbar = tqdm(total=max_depth, desc=\"Computing Nested Transport\", unit=\"depth\")\n",
    "\n",
    "    # Base case: if maximum depth reached, no further cost.\n",
    "    if current_depth == max_depth:\n",
    "        return 0.0\n",
    "\n",
    "    # Retrieve children lists: each element is (key, (child_node, prob))\n",
    "    children1 = list(node1.children.items())\n",
    "    children2 = list(node2.children.items())\n",
    "\n",
    "    # If both nodes are terminal, return 0.\n",
    "    if not children1 and not children2:\n",
    "        return 0.0\n",
    "\n",
    "    n1 = len(children1)\n",
    "    n2 = len(children2)\n",
    "    cost_matrix = np.zeros((n1, n2))\n",
    "\n",
    "    # Compute the cost matrix between all pairs of children.\n",
    "    for i, (_, (child1, prob1)) in enumerate(children1):\n",
    "        for j, (_, (child2, prob2)) in enumerate(children2):\n",
    "            # Immediate cost for scalar states (d=1)\n",
    "            immediate_cost = abs(child1.value - child2.value) ** power\n",
    "            # Add the nested cost (future steps)\n",
    "            nested_cost = nested_transport_cost(child1, child2, current_depth + 1, max_depth, power, method, lambda_reg, pbar)\n",
    "            cost_matrix[i, j] = immediate_cost + nested_cost\n",
    "\n",
    "    # Update progress bar **only once per depth level**\n",
    "    if current_depth == 0:\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Get the children distributions (transition probabilities).\n",
    "    p = np.array([prob for (_, (child, prob)) in children1])\n",
    "    q = np.array([prob for (_, (child, prob)) in children2])\n",
    "\n",
    "    # Solve the optimal transport problem between p and q.\n",
    "    transport_plan = ot.lp.emd(p, q, cost_matrix)\n",
    "    total_cost = np.sum(transport_plan * cost_matrix)\n",
    "\n",
    "    # Close progress bar at the end of recursion\n",
    "    if current_depth == 0 and pbar is not None:\n",
    "        pbar.close()\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def compute_adapted_wasserstein_markov(tree1_root, tree2_root, max_depth, power=1, method=\"lp\", lambda_reg=1e-2):\n",
    "    \"\"\"\n",
    "    Computes the adapted Wasserstein (nested) distance between two Markov processes.\n",
    "    \n",
    "    The distance is computed recursively from the root nodes.\n",
    "    \n",
    "    Parameters:\n",
    "      tree1_root, tree2_root: Root nodes of the two Markov trees.\n",
    "      max_depth: Maximum depth (number of transitions) to consider.\n",
    "      power: Exponent in the cost (1 for absolute difference, 2 for squared difference, etc.).\n",
    "      method: Which OT solver to use (here we use \"lp\" for the linear programming solver).\n",
    "      lambda_reg: Regularization parameter (not used for the LP solver).\n",
    "    \n",
    "    Returns:\n",
    "      The adapted Wasserstein distance.\n",
    "    \"\"\"\n",
    "    return nested_transport_cost(tree1_root, tree2_root, current_depth=0, max_depth=max_depth, power=power, method=method, lambda_reg=lambda_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified uniform_empirical_grid_measure: supports both 2D (d=1) and 3D (d>1) sample paths.\n",
    "def uniform_empirical_grid_measure(data, delta_n=None, use_weights=False):\n",
    "    # If data is 2D, each path is a 1D sequence (d = 1).\n",
    "    if data.ndim == 2:\n",
    "        num_path, t = data.shape\n",
    "        if delta_n is None:\n",
    "            delta_n = 1 / (num_path ** (1 / t))\n",
    "        grid_func = lambda x: np.floor(x / delta_n + 0.5) * delta_n\n",
    "        quantized_data = grid_func(data)\n",
    "        quantized_data[:, 0] = data[:, 0]\n",
    "        if not use_weights:\n",
    "            return quantized_data\n",
    "        else:\n",
    "            unique_paths, indices, counts = np.unique(\n",
    "                quantized_data, axis=0, return_inverse=True, return_counts=True\n",
    "            )\n",
    "            weights = counts / num_path\n",
    "            return unique_paths, weights\n",
    "    # If data is 3D, each path has shape (T+1, d).\n",
    "    elif data.ndim == 3:\n",
    "        num_path, t, d = data.shape\n",
    "        if delta_n is None:\n",
    "            # For multi-dimensional paths, one may adjust the exponent as needed.\n",
    "            delta_n = 1 / (num_path ** (1 / t))\n",
    "        grid_func = lambda x: np.floor(x / delta_n + 0.5) * delta_n\n",
    "        quantized_data = grid_func(data)\n",
    "        quantized_data[:, 0, :] = data[:, 0, :]\n",
    "        if not use_weights:\n",
    "            return quantized_data\n",
    "        else:\n",
    "            # Convert each sample path (2D array) into a hashable tuple of tuples.\n",
    "            quantized_paths = [tuple(map(tuple, quantized_data[i])) for i in range(num_path)]\n",
    "            # Preserve the original order.\n",
    "            unique_paths_list = []\n",
    "            counts_list = []\n",
    "            for p in quantized_paths:\n",
    "                if p in unique_paths_list:\n",
    "                    counts_list[unique_paths_list.index(p)] += 1\n",
    "                else:\n",
    "                    unique_paths_list.append(p)\n",
    "                    counts_list.append(1)\n",
    "            weights = np.array(counts_list) / num_path\n",
    "            # Convert unique paths back to numpy arrays.\n",
    "            unique_paths = np.array([np.array(up) for up in unique_paths_list])\n",
    "            return unique_paths, weights\n",
    "    else:\n",
    "        raise ValueError(\"Data must be either 2D (d=1) or 3D (d>1).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/y0r78dbd0tqdhj5dcjps5fdh0000gn/T/ipykernel_19472/3752929263.py:136: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cost_matrix[i, j] = immediate_cost + nested_cost\n",
      "Computing Nested Transport:  17%|█▋        | 1/6 [00:55<04:38, 55.64s/depth]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapted Wasserstein Distance (Markov Processes): 73.18363159811074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set normalization flag (set to False to use L0 and M0 directly)\n",
    "normalize = False\n",
    "\n",
    "# Define the parameters for the 1D Markov process at 4 time steps\n",
    "L0 = 1.0\n",
    "L1 = 2.0\n",
    "L2 = 1.5\n",
    "L3 = 1.2\n",
    "\n",
    "# Off-diagonals (transition coefficients)\n",
    "A1 = 0.5\n",
    "A2 = 0.3\n",
    "A3 = 0.2\n",
    "\n",
    "# Construct the 4x4 lower-triangular matrix with the Markovian (banded) structure:\n",
    "L_markov = np.array([\n",
    "    [L0, 0,   0,   0],\n",
    "    [A1, L1,  0,   0],\n",
    "    [0,  A2, L2,   0],\n",
    "    [0,  0,  A3,  L3]\n",
    "])\n",
    "A0 = L_markov @ L_markov.T\n",
    "L = L_markov / np.sqrt(np.trace(A0)) if normalize else L_markov\n",
    "A = L @ L.T\n",
    "\n",
    "# Define the parameters for the 1D Markov process at 4 time steps\n",
    "M0 = 6.0\n",
    "M1 = 7.0\n",
    "M2 = 2.5\n",
    "M3 = 3.2\n",
    "\n",
    "# Off-diagonals (transition coefficients)\n",
    "B1 = 0.7\n",
    "B2 = 0.9\n",
    "B3 = 0.1\n",
    "\n",
    "# Construct the 4x4 lower-triangular matrix with the Markovian (banded) structure:\n",
    "M_markov = np.array([\n",
    "    [M0, 0,   0,   0],\n",
    "    [B1, M1,  0,   0],\n",
    "    [0,  B2, M2,   0],\n",
    "    [0,  0,  B3,  M3]\n",
    "])\n",
    "M0 = M_markov @ M_markov.T\n",
    "M = M_markov / np.sqrt(np.trace(M0)) if normalize else M_markov\n",
    "B = M @ M.T\n",
    "\n",
    "\n",
    "\n",
    "# Set dimension parameters: for d=2, T=3 (thus total dimension = 6)\n",
    "d = 1\n",
    "T = 4\n",
    "dim = d * T  # 4\n",
    "\n",
    "n_sample_plot = 500  # number of sample paths\n",
    "\n",
    "X_paths = []\n",
    "Y_paths = []\n",
    "for _ in range(n_sample_plot):\n",
    "    # Generate noise as a vector in R^{dim}\n",
    "    noise1 = np.random.normal(size=(dim,))  # shape: (6,)\n",
    "    noise2 = np.random.normal(size=(dim,))  # shape: (6,)\n",
    "    # Obtain increments: these are vectors in R^{dim} (6,)\n",
    "    X_increments = L @ noise1  # shape: (6,)\n",
    "    Y_increments = M @ noise2  # shape: (6,)\n",
    "    # Reshape into (T, d) = (3, 2)\n",
    "    X_increments = X_increments.reshape((T, d))\n",
    "    Y_increments = Y_increments.reshape((T, d))\n",
    "    # (Optionally, if you still want to prepend a zero step, do it here.)\n",
    "    X_sample = np.vstack([np.zeros((1, d)), X_increments])\n",
    "    Y_sample = np.vstack([np.zeros((1, d)), Y_increments])\n",
    "\n",
    "    X_paths.append(X_sample)\n",
    "    Y_paths.append(Y_sample)\n",
    "    \n",
    "X_paths = np.array(X_paths)  # shape: (160, 3, 2)\n",
    "Y_paths = np.array(Y_paths)  # shape: (160, 3, 2)\n",
    "\n",
    "# Adapt the empirical measure using uniform grid quantization.\n",
    "adapted_X, adapted_weights_X = uniform_empirical_grid_measure(X_paths, use_weights=True)\n",
    "adapted_Y, adapted_weights_Y = uniform_empirical_grid_measure(Y_paths, use_weights=True)\n",
    "\n",
    "# Build the recombining (Markov) trees.\n",
    "tree1 = build_markov_tree_from_paths(adapted_X, adapted_weights_X)\n",
    "tree2 = build_markov_tree_from_paths(adapted_Y, adapted_weights_Y)\n",
    "\n",
    "# Set maximum depth: here, each path has 4 states (3 transitions).\n",
    "max_depth = 6\n",
    "power = 2  # using absolute difference as cost\n",
    "\n",
    "# Compute the adapted Wasserstein distance between the two Markov processes.\n",
    "adapted_distance = compute_adapted_wasserstein_markov(tree1, tree2, max_depth, power)\n",
    "print(\"Adapted Wasserstein Distance (Markov Processes):\", adapted_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapted Wasserstein Squared Distance for custom Gaussian process: 55.41000000000001\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebooks_path = os.path.abspath(os.getcwd()) \n",
    "src_path = os.path.abspath(os.path.join(notebooks_path, \"../src\"))\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "from benchmark_value_gaussian.Comp_AWD2_Gaussian import *\n",
    "\n",
    "\n",
    "# Set dimension parameters: d = 2, T = 3 (thus total dimension = 6)\n",
    "d = 1\n",
    "T = 4\n",
    "dim = d * T\n",
    "\n",
    "# Define zero mean vectors for both processes in R^(d*T)\n",
    "a = np.zeros(dim)\n",
    "b = np.zeros(dim)\n",
    "\n",
    "# Compute the adapted Wasserstein squared distance for the custom Gaussian process\n",
    "distance_aw2 = adapted_wasserstein_squared(a, A, b, B, d, T)\n",
    "print(\"Adapted Wasserstein Squared Distance for custom Gaussian process:\", distance_aw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
